---
name: working-with-supabase
description: Work with Supabase (hosted Postgres) projects — CLI, migrations, seeding, schema introspection, and connecting Supabase as a warehouse for Lightdash or other analytics tools. Use when the user mentions Supabase, database connections, pooler, migrations, or seeding data.
---

# Working with Supabase

Manage Supabase projects, run migrations, seed data, and connect Supabase as a data warehouse for analytics tools like Lightdash.

## Quick Reference

| Task | Command / Action |
|------|-----------------|
| Install CLI | `brew install supabase/tap/supabase` |
| Login | `supabase login` |
| Link to hosted project | `supabase link` |
| Push migrations | `supabase db push` |
| Create migration | `supabase migration new <name>` |
| Grab table schema | See [Schema Introspection](#schema-introspection) |
| Connect to Lightdash | See [Connecting Supabase to Lightdash](#connecting-supabase-to-lightdash) |

## Setup & Project Linking

```bash
# Login
supabase login

# Link to an existing hosted project (interactive)
supabase link

# Link with project ref directly
supabase link --project-ref <project-ref>

# List projects
supabase projects list
```

### Get Connection Details

1. Open Supabase dashboard → your project → click **Connect** at top
2. Select **Shared Pooler** tab (not direct)
3. Click **View parameters** for host, port, user, database

> **Why shared pooler?** External services (Lightdash Cloud, analytics tools, CI) connect from their own infrastructure. The direct host (`db.xxxx.supabase.co`) may not resolve from outside Supabase's network. The shared pooler (`aws-0-*.pooler.supabase.com`) always works.

## Schema Introspection

Grab your table structure to feed to an AI copilot for model generation:

```sql
SELECT table_name, column_name, data_type
FROM information_schema.columns
WHERE table_schema = 'public'
ORDER BY table_name, ordinal_position;
```

Run this in the Supabase **SQL Editor** or via psql. Copy the output — it's the fastest way to generate Lightdash models, dbt schemas, or any ORM type definitions.

## CLI Reference

### Migrations

```bash
# Create a new migration
supabase migration new <migration_name>
# → creates supabase/migrations/YYYYMMDDHHMMSS_<migration_name>.sql

# Push pending migrations to remote
supabase db push

# List migration status (local vs remote)
supabase migration list

# Pull remote schema changes into a new migration
supabase db pull

# Diff local vs remote schema
supabase db diff

# Reset local database (destructive — drops and recreates)
supabase db reset
```

Migration files live in `supabase/migrations/` and run in timestamp order. Write standard Postgres DDL:

```sql
CREATE TABLE IF NOT EXISTS public.my_readings (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    recorded_at TIMESTAMPTZ NOT NULL,
    sensor_name TEXT,
    value DOUBLE PRECISION
);
```

### Local Development

```bash
# Start local Supabase stack (Postgres, Auth, Storage, etc.)
supabase start

# Stop local stack
supabase stop

# Check status + connection details
supabase status
supabase status -o env   # DATABASE_URL, ANON_KEY, SERVICE_ROLE_KEY
```

### Database Operations

```bash
# Dump remote database
supabase db dump -f dump.sql

# Dump specific schema
supabase db dump -f dump.sql --schema public

# Dump data only (useful for generating seed files)
supabase db dump -f seed.sql --data-only --schema public
```

### Type Generation

```bash
# Generate TypeScript types from remote schema
supabase gen types typescript --linked > src/types/supabase.ts

# From local database
supabase gen types typescript --local > src/types/supabase.ts
```

### Edge Functions

```bash
supabase functions new <name>      # Create
supabase functions serve           # Serve locally
supabase functions deploy <name>   # Deploy one
supabase functions deploy          # Deploy all
```

### Connection Strings

```
# Local development
postgresql://postgres:postgres@127.0.0.1:54322/postgres

# Remote (via shared pooler — use this for external services)
postgresql://postgres.PROJECT_REF:PASSWORD@aws-0-REGION.pooler.supabase.com:6543/postgres

# Remote (direct — only works from same network / allowed IPs)
postgresql://postgres.PROJECT_REF:PASSWORD@db.PROJECT_REF.supabase.co:5432/postgres
```

### Useful Flags

| Flag | Purpose |
|------|---------|
| `--project-ref` | Specify project without interactive prompt |
| `--linked` | Use the linked remote project |
| `--local` | Use the local development database |
| `-f, --file` | Output file path |
| `--schema` | Target specific schema(s) |
| `--debug` | Verbose logging for troubleshooting |

### Command Summary

| Command | Purpose |
|---------|---------|
| `supabase login` | Authenticate CLI |
| `supabase link` | Link to hosted project |
| `supabase start` / `stop` | Manage local dev stack |
| `supabase db push` | Push migrations to remote |
| `supabase db pull` | Pull remote schema changes |
| `supabase migration new` | Create migration file |
| `supabase migration list` | Check migration status |
| `supabase db dump` | Export database / data |
| `supabase gen types` | Generate TypeScript types |
| `supabase functions deploy` | Deploy edge functions |
| `supabase status` | Check local service status |

## Seeding Data

Supabase doesn't have a built-in seed command for remote. Use psql through the pooler:

```bash
# Install psql if needed (Mac — keg-only, won't conflict with system Postgres)
brew install libpq

# Seed via pooler connection string
/opt/homebrew/opt/libpq/bin/psql "postgresql://postgres.PROJECT_REF:PASSWORD@aws-0-REGION.pooler.supabase.com:6543/postgres" \
  -f supabase/seed.sql
```

When exporting from SQLite, CSV, or other sources:
- Empty fields become `, ,` not `NULL` — handle in your export script
- Use `INSERT INTO ... VALUES` with explicit `NULL` for missing values
- Batch inserts (100–500 rows per statement) for performance
- Wrap in a transaction for atomicity

## Connecting Supabase to Lightdash

### Step 1: Get connection details

Use the shared pooler parameters from the Supabase dashboard (see [Get Connection Details](#get-connection-details)).

### Step 2: Configure in Lightdash

**New project (setup wizard):**
1. Click **"Create manually"**
2. Click **"I've already defined them"** (the metrics prompt is dbt-centric — ignore it)
3. Fill in the connection form below

**Existing project:** Settings → Project → Warehouse Connection

### Connection form values

| Field | Value |
|-------|-------|
| **Warehouse type** | PostgreSQL |
| **Host** | Shared pooler host (e.g. `aws-0-us-east-1.pooler.supabase.com`) |
| **Database** | `postgres` |
| **User** | `postgres.YOUR_PROJECT_REF` (full string — note the dot, not a slash) |
| **Password** | Database password from project creation |

### Advanced settings (critical — not optional)

Click **Advanced** to expand. These look optional but will break your connection if not set:

| Field | Value | Why |
|-------|-------|-----|
| **Port** | `6543` (transaction mode) or `5432` (session mode) | Must match what Supabase shows |
| **SSL mode** | **`no-verify`** | Required. Default and `require` both fail with "self-signed certificate in certificate chain" |

For the **dbt project** section: select **"CLI"** and ignore the rest. Irrelevant for Lightdash YAML users but required to proceed.

### Step 3: Save, test & verify

Click **Save & Test**, then verify with a real query:

```bash
lightdash sql "SELECT 1 as test" -o test.csv
```

Or use **SQL Runner** in the Lightdash UI. "Save & Test" reports success without actually verifying the connection — you need a real query to confirm.

### Lightdash troubleshooting

| Symptom | Cause | Fix |
|---------|-------|-----|
| `ENOTFOUND` | Using direct host | Switch to shared pooler host |
| "self-signed certificate in certificate chain" | Wrong SSL mode | Set SSL to `no-verify` in Advanced |
| "password authentication failed" | Wrong user format | Must be `postgres.PROJECT_REF` (with dot) |
| "connection refused" on port 5432 | Wrong port for pooler | Transaction pooler uses `6543` |
| Save & Test succeeds but queries fail | Test doesn't verify connection | Check SSL mode and port |
| "relation does not exist" | Wrong schema | Ensure tables are in `public` schema |

### Connection architecture

```
Lightdash Cloud  →  Supabase Shared Pooler  →  Supabase Postgres
(their servers)     (aws-0-*.pooler.*)          (your database)
                    Port 6543 (transaction)
                    SSL: no-verify
```

### For other tools (Metabase, Grafana, etc.)

Same connection details. Key rules:
- Always use the **shared pooler** host, not direct
- Set SSL to `no-verify` or equivalent
- User format is always `postgres.PROJECT_REF`

## Gotchas

| Issue | Fix |
|-------|-----|
| `ENOTFOUND` on direct host from external service | Use shared pooler host instead |
| "self-signed certificate in certificate chain" | Set SSL mode to `no-verify` |
| `require` SSL mode still fails | Supabase pooler certs aren't in standard CA bundles — must use `no-verify` |
| psql not found on Mac | `brew install libpq` — keg-only at `/opt/homebrew/opt/libpq/bin/psql` |
| Empty CSV fields import as empty strings | Convert to `NULL` in your seed generation script |
| `supabase db push` hangs | Check you're linked (`supabase link`) and have network access |
| Connection works locally but not from cloud service | Cloud services can't reach direct host — switch to pooler |

## Resources

- [Supabase Docs](https://supabase.com/docs)
- [Supabase CLI Reference](https://supabase.com/docs/reference/cli)
- [Supabase Connection Pooling](https://supabase.com/docs/guides/database/connecting-to-postgres#connection-pooler)
